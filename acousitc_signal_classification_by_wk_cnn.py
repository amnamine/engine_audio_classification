# -*- coding: utf-8 -*-
"""Acousitc Signal Classification by WK-CNN

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/amineipad/acousitc-signal-classification-by-wk-cnn.93fcb222-a17b-4e17-a35c-8f5c2402de84.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20250421/auto/storage/goog4_request%26X-Goog-Date%3D20250421T142420Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Da19ace89d24c91957af276a39ad9d21903d9f9dc1740810c8881ff61145a1f13a0b8d4e07e726da2562d6d5f4f3cb7d793d9cca83ffae611a1d7a6bd7f753e5773ced6de3a649fb995ed7eec6397da310b6b6c78563e4f7086edb6ecea4a6520b8633ded685353a4927aa855483fbfe42eccea96f0e72e54668fafb52ea6e9b31d2fc1b85ca060da3510a897a3ab4b0ce945e014d728a39bae9d980d399538224b5281d18b5837c5a785a80ebf20089e2e24c1407ec9034df623648c0668a2e7c393c870455b2ea5d046a7a93c23ae846d16f18e2fa063c31cc67b313581e410295586aa780620c6fba5283fd1233ccffa3156833e281d1e959d4ed5ffc3b718
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.
import kagglehub
julienjta_engine_acoustic_emissions_path = kagglehub.dataset_download('julienjta/engine-acoustic-emissions')

print('Data source import complete.')

"""# Installing *torch-summary*"""

!pip install torch-summary

"""# Importing necessary libraries"""

import scipy
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import torch
import torch.nn.functional as F
from torchsummary import summary
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import seaborn as sns
sns.set()

"""# Checking if GPU is available"""

if torch.cuda.is_available():
  device = torch.device("cuda:0")
  print("GPU Runtime Detected")

else:
  device = torch.device("cpu")
  print("No GPU Found - CPU Runtime")

"""# Defining the *splitter* function"""

def splitter(array, win_len, hop_len, return_df = True):
   N = array.shape[0]
   m = 0
   ids = []
   while m + win_len < N:
      ids.append([m, m + win_len])
      m = m + hop_len

   if return_df:
      return pd.DataFrame([array[i[0]: i[1]] for i in ids])
   else:
      return np.array([array[i[0]: i[1]] for i in ids])

"""# Loading the Dataset"""

file = "../input/engine-acoustic-emissions/dataset.mat"
dataset = scipy.io.loadmat(file)
dataset.keys()

"""# Preprocessing

## Splitting the original Dataset
"""

win_len, hop_len = 8000, 1000
df_list = []

for state in ['normal', 'inner', 'roller', 'outer']:
    temp_df = splitter(dataset[state].reshape((-1,)), win_len, hop_len, return_df = True)
    temp_df['state'] = state
    df_list.append(temp_df)

df = pd.concat(df_list).reset_index(drop = True)
df

"""## Train/Test Splitting"""

df_train, df_test = train_test_split(df, test_size = 0.3, random_state = 42)

"""## Feature/Target Declaration"""

x_train, x_test = df_train.iloc[:, :-1], df_test.iloc[:, :-1]
y_train, y_test = df_train.iloc[:, -1], df_test.iloc[:, -1]

"""## Feature Scaling"""

def time_series_scaler(df):

  array_mu = np.mean(df.to_numpy(), axis = 1)
  array_sig = np.std(df.to_numpy(), axis = 1)

  array_scaled = (np.subtract(df.to_numpy().transpose(), array_mu) / array_sig).transpose()

  return array_scaled

x_train_scaled, x_test_scaled = time_series_scaler(x_train), time_series_scaler(x_test)

"""## Target Encoding"""

labelencoder= LabelEncoder()
y_train_encoded = labelencoder.fit_transform(y_train.to_numpy())
y_test_encoded = labelencoder.transform(y_test.to_numpy())

"""# Training

## Model Declaration
"""

class Classifier(torch.nn.Module):
    def __init__(self):
        super(Classifier, self).__init__()

        self.conv = torch.nn.Conv1d(in_channels = 1, out_channels = 5, kernel_size = 500)
        self.avgPool = torch.nn.AvgPool1d(kernel_size = 100)
        self.fc = torch.nn.Linear(5 * 75, 4)

    def forward(self, x):

        z = self.conv(x)
        z = torch.tanh(z)
        z = self.avgPool(z)

        z = z.view(-1, 5 * 75)

        z = self.fc(z)

        return z

model = Classifier().to(device)
summary(model, (1, 8000));

"""## Fitting the Model"""

x_train_train, x_train_validation, y_train_train, y_train_validation = train_test_split(x_train_scaled, y_train_encoded, test_size = 0.25)

x_train_train = x_train_train.reshape(-1, 1, 8000)
x_train_validation = x_train_validation.reshape(-1, 1, 8000)

x_train_VAR = torch.autograd.Variable(torch.Tensor(x_train_train).float()).to(device)
y_train_VAR = torch.autograd.Variable(torch.LongTensor(y_train_train)).to(device)
x_valid_VAR = torch.autograd.Variable(torch.Tensor(x_train_validation).float()).to(device)
y_valid_VAR = torch.autograd.Variable(torch.LongTensor(y_train_validation)).to(device)

lr = 0.005
ep = 150

model = Classifier().to(device)

criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(),
                             lr = lr,
                             weight_decay = lr / ep)

losses = []
valid_losses = []
accs = []
valid_accs = []



for epoch in range(ep):

  # validation step
  valid_loss = criterion(model(x_valid_VAR), y_valid_VAR).item()
  valid_losses.append(valid_loss)
  valid_acc = accuracy_score(y_train_validation, np.argmax(model(x_valid_VAR).cpu().detach().numpy(), axis = 1))
  valid_accs.append(valid_acc)

  # training step
  optimizer.zero_grad()
  loss = criterion(model(x_train_VAR), y_train_VAR)
  acc = accuracy_score(y_train_train, np.argmax(model(x_train_VAR).cpu().detach().numpy(), axis = 1))
  accs.append(acc)
  losses.append(loss.item())
  loss.backward()
  optimizer.step()
  print(f"Epoch {epoch+1}, loss: {np.round(loss.item(), 4)}  , Vloss: {np.round(valid_loss, 4)}, acc: {np.round(acc, 4)}, Vacc: {np.round(valid_acc, 4)}")

fig, axes = plt.subplots(1, 2, figsize=(16,4))
fig.suptitle('Deep Learning Model Training Process')
axes[0].plot(losses, label='Training Loss')
axes[0].plot(valid_losses, label='Validation Loss')
axes[0].set_xlabel('Epochs')
axes[0].set_ylabel('Loss')
axes[0].set_title('Loss Vs. Epochs')
axes[0].legend()

axes[1].plot(accs, label='Training Accuracy')
axes[1].plot(valid_accs, label='Validation Accuracy')
axes[1].set_xlabel('Epochs')
axes[1].set_ylabel('Accuracy')
axes[1].set_title('Accuracy Vs. Epochs')
axes[1].legend()
plt.show()

"""# Evaluation

## Test-set Accuracy
"""

x_test_VAR = torch.autograd.Variable(torch.Tensor(x_test_scaled.reshape(-1, 1, 8000)).float()).to(device)
testing_acc = accuracy_score(y_test_encoded, np.argmax(F.softmax(model(x_test_VAR), dim = 0).cpu().detach().numpy(), axis = 1))
print('Held-out Test-set Accuracy: ', round(testing_acc, 4))

"""## Test-set Confusion Matrix"""

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

y_test_pred = np.argmax(F.softmax(model(x_test_VAR), dim = 0).cpu().detach().numpy(), axis = 1)
y_test_pred_decoded = labelencoder.inverse_transform(y_test_pred)
ax.set_ylabel("Actual", fontsize=14, labelpad=20)
ax.yaxis.set_ticklabels(np.unique(y_test_pred_decoded))
ax.set_title("Confusion Matrix", fontsize=14, pad=20)
plt.show()