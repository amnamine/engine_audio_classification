{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4213131,"sourceType":"datasetVersion","datasetId":2483760}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Installing *torch-summary*","metadata":{}},{"cell_type":"code","source":"!pip install torch-summary","metadata":{"execution":{"iopub.status.busy":"2025-04-21T11:37:35.497968Z","iopub.execute_input":"2025-04-21T11:37:35.498316Z","iopub.status.idle":"2025-04-21T11:37:44.790610Z","shell.execute_reply.started":"2025-04-21T11:37:35.498281Z","shell.execute_reply":"2025-04-21T11:37:44.789743Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Importing necessary libraries","metadata":{}},{"cell_type":"code","source":"import scipy\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport torch\nimport torch.nn.functional as F\nfrom torchsummary import summary\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()","metadata":{"execution":{"iopub.status.busy":"2025-04-21T11:37:44.792753Z","iopub.execute_input":"2025-04-21T11:37:44.793496Z","iopub.status.idle":"2025-04-21T11:37:49.113074Z","shell.execute_reply.started":"2025-04-21T11:37:44.793444Z","shell.execute_reply":"2025-04-21T11:37:49.112401Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Checking if GPU is available","metadata":{}},{"cell_type":"code","source":"if torch.cuda.is_available():\n  device = torch.device(\"cuda:0\")\n  print(\"GPU Runtime Detected\")\n\nelse:\n  device = torch.device(\"cpu\")\n  print(\"No GPU Found - CPU Runtime\")","metadata":{"execution":{"iopub.status.busy":"2025-04-21T11:37:49.114132Z","iopub.execute_input":"2025-04-21T11:37:49.114500Z","iopub.status.idle":"2025-04-21T11:37:49.140760Z","shell.execute_reply.started":"2025-04-21T11:37:49.114472Z","shell.execute_reply":"2025-04-21T11:37:49.139827Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Defining the *splitter* function","metadata":{}},{"cell_type":"code","source":"def splitter(array, win_len, hop_len, return_df = True):\n   N = array.shape[0]\n   m = 0\n   ids = []\n   while m + win_len < N:\n      ids.append([m, m + win_len])\n      m = m + hop_len\n      \n   if return_df:\n      return pd.DataFrame([array[i[0]: i[1]] for i in ids])\n   else:\n      return np.array([array[i[0]: i[1]] for i in ids])","metadata":{"execution":{"iopub.status.busy":"2025-04-21T11:37:49.142819Z","iopub.execute_input":"2025-04-21T11:37:49.143107Z","iopub.status.idle":"2025-04-21T11:37:49.154789Z","shell.execute_reply.started":"2025-04-21T11:37:49.143080Z","shell.execute_reply":"2025-04-21T11:37:49.153806Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Loading the Dataset","metadata":{}},{"cell_type":"code","source":"file = \"../input/engine-acoustic-emissions/dataset.mat\"\ndataset = scipy.io.loadmat(file)\ndataset.keys()","metadata":{"execution":{"iopub.status.busy":"2025-04-21T11:37:49.155700Z","iopub.execute_input":"2025-04-21T11:37:49.155944Z","iopub.status.idle":"2025-04-21T11:37:49.311272Z","shell.execute_reply.started":"2025-04-21T11:37:49.155920Z","shell.execute_reply":"2025-04-21T11:37:49.310399Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"markdown","source":"## Splitting the original Dataset","metadata":{}},{"cell_type":"code","source":"win_len, hop_len = 8000, 1000\ndf_list = []\n\nfor state in ['normal', 'inner', 'roller', 'outer']:\n    temp_df = splitter(dataset[state].reshape((-1,)), win_len, hop_len, return_df = True)\n    temp_df['state'] = state\n    df_list.append(temp_df)\n\ndf = pd.concat(df_list).reset_index(drop = True)\ndf","metadata":{"execution":{"iopub.status.busy":"2025-04-21T11:37:49.312522Z","iopub.execute_input":"2025-04-21T11:37:49.313235Z","iopub.status.idle":"2025-04-21T11:37:50.546560Z","shell.execute_reply.started":"2025-04-21T11:37:49.313193Z","shell.execute_reply":"2025-04-21T11:37:50.545645Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Train/Test Splitting","metadata":{}},{"cell_type":"code","source":"df_train, df_test = train_test_split(df, test_size = 0.3, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2025-04-21T11:37:50.547634Z","iopub.execute_input":"2025-04-21T11:37:50.547887Z","iopub.status.idle":"2025-04-21T11:37:50.573069Z","shell.execute_reply.started":"2025-04-21T11:37:50.547862Z","shell.execute_reply":"2025-04-21T11:37:50.572402Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Feature/Target Declaration","metadata":{}},{"cell_type":"code","source":"x_train, x_test = df_train.iloc[:, :-1], df_test.iloc[:, :-1]\ny_train, y_test = df_train.iloc[:, -1], df_test.iloc[:, -1]","metadata":{"execution":{"iopub.status.busy":"2025-04-21T11:37:50.574165Z","iopub.execute_input":"2025-04-21T11:37:50.574517Z","iopub.status.idle":"2025-04-21T11:37:50.590693Z","shell.execute_reply.started":"2025-04-21T11:37:50.574478Z","shell.execute_reply":"2025-04-21T11:37:50.589907Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Defining *STFT* function","metadata":{}},{"cell_type":"code","source":"def stft(signals, window_len, hop_len, freq_filter = None, window = None):\n  \"\"\"\n  STFT(signals, window_len, hop_len, freq_filter = None, window = None) - Application of Short-Time Fourier Transform to derive Time-Frequency representation of the inputted signals\n\n  Arguemnts:\n  signals -- A pd.DataFrame() incuding signals in its rows.\n  window_len -- Lenght of the desired time segments.\n  hop_len -- Length of the feed, used to get forward during the segmentation process.\n  freq_filter -- A frequency filter object from scipy.signal module (e.g. scipy.signal.butter()) to avoid aliasing.\n  window -- A window object from scipy.signal.windows module (e.g. scipy.signal.windows.hann()) to encounter the leakage error.\n\n  Return Value:\n  A np.array(), whose first dimension equals the number of rows included in the input pd.DataFrame; it includes derived Time-Frequency representations of the inputted signals. freq_filter and window are not mandatory \n  arguments and a function call without them is valid, however, we recommend using them to avoid aliasing (and of course near-zero/DC filtering through band-pass filters) and leakage error. Pay attention that unlike\n  the case of damavand.signal_processing.fft() or damavand.signal_processing.zoomed_fft(), for this function you have to define freq_filter and window objects with a lenght that suits the segmented signals (equal to\n  the window_len argument), instead of the original signals, presented in the inputted pd.DataFrame().\n\n  Descriptions:\n  By the application of this function, one is able to derive Time-Frequency representation; this is done by first segmenting the original signals to a series of shorter signals and consecutively FFT is applied on each\n  segmented signal to derive the corresponding frequency representation. Results are usually visualized as heatmaps, whose vertical axis is the frequency dimension and the horizontal one is left to time dimension. One\n  can use the damavand.utils.STFT_axises() to generate both time and frequency axises needed to visualize the resulting heatmaps.\n  \"\"\"\n  splitted_signals = np.array(signals.apply(splitter, args = (window_len, hop_len, False), axis = 1).to_list())\n  if freq_filter is not None:\n    splitted_signals = scipy.signal.sosfilt(freq_filter, splitted_signals)\n\n  if window is not None:\n    splitted_signals = splitted_signals * window\n\n  return 2.0/splitted_signals.shape[2] * np.abs(scipy.fft.fft(splitted_signals)[:, :, 0:splitted_signals.shape[2]//2])","metadata":{"execution":{"iopub.status.busy":"2025-04-21T11:37:50.591656Z","iopub.execute_input":"2025-04-21T11:37:50.591888Z","iopub.status.idle":"2025-04-21T11:37:50.598278Z","shell.execute_reply.started":"2025-04-21T11:37:50.591865Z","shell.execute_reply":"2025-04-21T11:37:50.597374Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## STFT","metadata":{}},{"cell_type":"code","source":"STFT_window = scipy.signal.windows.hann(1000)\nSTFT_freq_filter = scipy.signal.butter(25, [5, 4500], 'bandpass', fs = 10000, output='sos')\nx_train_STFT = stft(x_train, 1000, 100, STFT_freq_filter, STFT_window)\nx_test_STFT = stft(x_test, 1000, 100, STFT_freq_filter, STFT_window)\nprint(x_train_STFT.shape, x_test_STFT.shape)","metadata":{"execution":{"iopub.status.busy":"2025-04-21T11:37:50.600830Z","iopub.execute_input":"2025-04-21T11:37:50.601081Z","iopub.status.idle":"2025-04-21T11:37:55.156308Z","shell.execute_reply.started":"2025-04-21T11:37:50.601056Z","shell.execute_reply":"2025-04-21T11:37:55.155389Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Feature Scaling","metadata":{}},{"cell_type":"code","source":"x_train_STFT_scaled = []\nfor i in range(x_train_STFT.shape[0]):\n    x_train_STFT_scaled.append(x_train_STFT[i, :, :] / np.max(x_train_STFT[i, :, :]))\n    \nx_train_STFT_scaled = np.array(x_train_STFT_scaled)\nx_train_STFT_scaled.shape","metadata":{"execution":{"iopub.status.busy":"2025-04-21T11:37:55.157389Z","iopub.execute_input":"2025-04-21T11:37:55.157788Z","iopub.status.idle":"2025-04-21T11:37:55.263690Z","shell.execute_reply.started":"2025-04-21T11:37:55.157758Z","shell.execute_reply":"2025-04-21T11:37:55.262868Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x_test_STFT_scaled = []\nfor i in range(x_test_STFT.shape[0]):\n    x_test_STFT_scaled.append(x_test_STFT[i, :, :] / np.max(x_test_STFT[i, :, :]))\n    \nx_test_STFT_scaled = np.array(x_test_STFT_scaled)\nx_test_STFT_scaled.shape","metadata":{"execution":{"iopub.status.busy":"2025-04-21T11:37:55.264834Z","iopub.execute_input":"2025-04-21T11:37:55.265200Z","iopub.status.idle":"2025-04-21T11:37:55.299416Z","shell.execute_reply.started":"2025-04-21T11:37:55.265151Z","shell.execute_reply":"2025-04-21T11:37:55.298542Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Target Encoding","metadata":{}},{"cell_type":"code","source":"labelencoder= LabelEncoder()\ny_train_encoded = labelencoder.fit_transform(y_train.to_numpy())\ny_test_encoded = labelencoder.transform(y_test.to_numpy())","metadata":{"execution":{"iopub.status.busy":"2025-04-21T11:37:55.300413Z","iopub.execute_input":"2025-04-21T11:37:55.300683Z","iopub.status.idle":"2025-04-21T11:37:55.305043Z","shell.execute_reply.started":"2025-04-21T11:37:55.300657Z","shell.execute_reply":"2025-04-21T11:37:55.304202Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"markdown","source":"## Model Declaration","metadata":{}},{"cell_type":"code","source":"class Classifier(torch.nn.Module):\n    def __init__(self):\n        super(Classifier, self).__init__()\n\n        self.conv = torch.nn.Conv2d(in_channels = 1, out_channels = 5, kernel_size = 5)\n        self.avgPool = torch.nn.AvgPool2d(kernel_size = 5)\n        self.fc = torch.nn.Linear(5 * 13 * 99, 4)\n\n    def forward(self, x):\n\n        z = self.conv(x)\n        z = torch.tanh(z)\n        z = self.avgPool(z)\n\n        z = z.view(-1, 5 * 13 * 99)\n\n        z = self.fc(z)\n\n        return z","metadata":{"execution":{"iopub.status.busy":"2025-04-21T11:37:55.306007Z","iopub.execute_input":"2025-04-21T11:37:55.306329Z","iopub.status.idle":"2025-04-21T11:37:55.316756Z","shell.execute_reply.started":"2025-04-21T11:37:55.306283Z","shell.execute_reply":"2025-04-21T11:37:55.316097Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = Classifier().to(device)\nsummary(model, (1, 70, 500));","metadata":{"execution":{"iopub.status.busy":"2025-04-21T11:37:55.317565Z","iopub.execute_input":"2025-04-21T11:37:55.317793Z","iopub.status.idle":"2025-04-21T11:37:56.024795Z","shell.execute_reply.started":"2025-04-21T11:37:55.317769Z","shell.execute_reply":"2025-04-21T11:37:56.023944Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Fitting the Model","metadata":{}},{"cell_type":"code","source":"x_train_train, x_train_validation, y_train_train, y_train_validation = train_test_split(x_train_STFT_scaled, y_train_encoded, test_size = 0.25)\n\nx_train_train = x_train_train.reshape(-1, 1, 70, 500)\nx_train_validation = x_train_validation.reshape(-1, 1, 70, 500)\n\nx_train_VAR = torch.autograd.Variable(torch.Tensor(x_train_train).float()).to(device)\ny_train_VAR = torch.autograd.Variable(torch.LongTensor(y_train_train)).to(device)\nx_valid_VAR = torch.autograd.Variable(torch.Tensor(x_train_validation).float()).to(device)\ny_valid_VAR = torch.autograd.Variable(torch.LongTensor(y_train_validation)).to(device)","metadata":{"execution":{"iopub.status.busy":"2025-04-21T11:37:56.026036Z","iopub.execute_input":"2025-04-21T11:37:56.026430Z","iopub.status.idle":"2025-04-21T11:37:56.101882Z","shell.execute_reply.started":"2025-04-21T11:37:56.026387Z","shell.execute_reply":"2025-04-21T11:37:56.100915Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lr = 0.005\nep = 50\n\nmodel = Classifier().to(device)\n\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(),\n                             lr = lr,\n                             weight_decay = lr / ep)\n\nlosses = []\nvalid_losses = []\naccs = []\nvalid_accs = []\n\n\n\nfor epoch in range(ep):\n\n  # validation step\n  valid_loss = criterion(model(x_valid_VAR), y_valid_VAR).item()\n  valid_losses.append(valid_loss)\n  valid_acc = accuracy_score(y_train_validation, np.argmax(model(x_valid_VAR).cpu().detach().numpy(), axis = 1))\n  valid_accs.append(valid_acc)\n\n  # training step\n  optimizer.zero_grad()\n  loss = criterion(model(x_train_VAR), y_train_VAR)\n  acc = accuracy_score(y_train_train, np.argmax(model(x_train_VAR).cpu().detach().numpy(), axis = 1))\n  accs.append(acc)\n  losses.append(loss.item())\n  loss.backward()\n  optimizer.step()\n  print(f\"Epoch {epoch+1}, loss: {np.round(loss.item(), 4)}  , Vloss: {np.round(valid_loss, 4)}, acc: {np.round(acc, 4)}, Vacc: {np.round(valid_acc, 4)}\")","metadata":{"execution":{"iopub.status.busy":"2025-04-21T11:37:56.102972Z","iopub.execute_input":"2025-04-21T11:37:56.103245Z","iopub.status.idle":"2025-04-21T11:37:58.549825Z","shell.execute_reply.started":"2025-04-21T11:37:56.103218Z","shell.execute_reply":"2025-04-21T11:37:58.548998Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, figsize=(16,4))\nfig.suptitle('Deep Learning Model Training Process')\naxes[0].plot(losses, label='Training Loss')\naxes[0].plot(valid_losses, label='Validation Loss')\naxes[0].set_xlabel('Epochs')\naxes[0].set_ylabel('Loss')\naxes[0].set_title('Loss Vs. Epochs')\naxes[0].legend()\n\naxes[1].plot(accs, label='Training Accuracy')\naxes[1].plot(valid_accs, label='Validation Accuracy')\naxes[1].set_xlabel('Epochs')\naxes[1].set_ylabel('Accuracy')\naxes[1].set_title('Accuracy Vs. Epochs')\naxes[1].legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2025-04-21T11:37:58.551036Z","iopub.execute_input":"2025-04-21T11:37:58.551605Z","iopub.status.idle":"2025-04-21T11:37:59.110124Z","shell.execute_reply.started":"2025-04-21T11:37:58.551561Z","shell.execute_reply":"2025-04-21T11:37:59.109292Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"markdown","source":"## Test-set Accuracy","metadata":{}},{"cell_type":"code","source":"x_test_VAR = torch.autograd.Variable(torch.Tensor(x_test_STFT_scaled.reshape(-1, 1, 70, 500)).float()).to(device)\ntesting_acc = accuracy_score(y_test_encoded, np.argmax(F.softmax(model(x_test_VAR), dim = 0).cpu().detach().numpy(), axis = 1))\nprint('Held-out Test-set Accuracy: ', round(testing_acc, 4))","metadata":{"execution":{"iopub.status.busy":"2025-04-21T11:37:59.111335Z","iopub.execute_input":"2025-04-21T11:37:59.111701Z","iopub.status.idle":"2025-04-21T11:37:59.136561Z","shell.execute_reply.started":"2025-04-21T11:37:59.111665Z","shell.execute_reply":"2025-04-21T11:37:59.135667Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Test-set Confusion Matrix","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\ny_test_pred = np.argmax(F.softmax(model(x_test_VAR), dim = 0).cpu().detach().numpy(), axis = 1)\ny_test_pred_decoded = labelencoder.inverse_transform(y_test_pred)\n\nmatrix = confusion_matrix(y_test_encoded, y_test_pred)\n\nax = sns.heatmap(matrix, annot=True, fmt='d', cbar = True, square = True, cmap = 'Blues')\nax.set_xlabel(\"Predicted\", fontsize=14, labelpad=20)\nax.xaxis.set_ticklabels(np.unique(y_test_pred_decoded))\nax.set_ylabel(\"Actual\", fontsize=14, labelpad=20)\nax.yaxis.set_ticklabels(np.unique(y_test_pred_decoded))\nax.set_title(\"Confusion Matrix\", fontsize=14, pad=20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2025-04-21T11:37:59.138305Z","iopub.execute_input":"2025-04-21T11:37:59.138730Z","iopub.status.idle":"2025-04-21T11:37:59.457196Z","shell.execute_reply.started":"2025-04-21T11:37:59.138685Z","shell.execute_reply":"2025-04-21T11:37:59.456306Z"},"trusted":true},"outputs":[],"execution_count":null}]}